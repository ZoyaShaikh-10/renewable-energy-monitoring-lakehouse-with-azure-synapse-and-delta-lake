{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd3bdb29-e846-4131-bc13-e89d40ec4909",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import *\n",
    "\n",
    "# Initialize Spark session with Delta support\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DeltaLakeSetup\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"fs.azure.account.key.azddevstorage.dfs.core.windows.net\", \"YOUR_STORAGE_ACCOUNT_KEY_HERE\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c1e74c7-f123-4a38-9ef7-ce672b9d3e36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, TimestampType\n",
    "\n",
    "# Define schemas\n",
    "# Define the improved schema \n",
    "consumption_batch_schema = StructType([\n",
    "    StructField(\"date\", TimestampType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"residential_consumption\", FloatType(), True),\n",
    "    StructField(\"commercial_consumption\", FloatType(), True),\n",
    "    StructField(\"industrial_consumption\", FloatType(), True)\n",
    "])\n",
    "\n",
    "consumption_real_time_schema = StructType([\n",
    "    StructField(\"time\", TimestampType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"latitude\", FloatType(), True),\n",
    "    StructField(\"longitude\", FloatType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"energy_consumption_kWh\", FloatType(), True)\n",
    "])\n",
    "\n",
    "# Define the production schema (same for both batch and real-time)\n",
    "production_schema = StructType([\n",
    "    StructField(\"time\", TimestampType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"solar_energy\", FloatType(), True),\n",
    "    StructField(\"wind_energy\", FloatType(), True),\n",
    "    StructField(\"hydro_energy\", FloatType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18e4816e-3992-495f-82eb-6607d5500752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing Consumption Batch data for location: Boston...\n",
      "[INFO] Checking paths for consumption batch data in Boston...\n",
      "[INFO] Loaded consumption data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/batch/Boston/consumption_batch_data/.\n",
      "[INFO] Writing consumption data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/Boston/consumption_data/\n",
      "[INFO] Consumption data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/Boston/consumption_data/.\n",
      "[INFO] Processing Production Batch data for location: Boston...\n",
      "[INFO] Checking paths for production batch data in Boston...\n",
      "[INFO] Loaded production data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/batch/Boston/production_batch_data/.\n",
      "[INFO] Writing production data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/Boston/production_data/\n",
      "[INFO] Production data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/Boston/production_data/.\n",
      "****************************************\n",
      "[INFO] Processing Consumption Real-time data for location: Boston...\n",
      "[INFO] Checking paths for consumption real-time data in Boston...\n",
      "[INFO] Loaded consumption data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/real-time/Boston/energy_consumption/.\n",
      "[INFO] Writing consumption data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/Boston/energy_consumption_data/\n",
      "[INFO] Consumption data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/Boston/energy_consumption_data/.\n",
      "[INFO] Processing Production Real-time data for location: Boston...\n",
      "[INFO] Checking paths for production real-time data in Boston...\n",
      "[INFO] Loaded production data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/real-time/Boston/production_simulation/.\n",
      "[INFO] Writing production data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/Boston/production_simulation_data/\n",
      "[INFO] Production data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/Boston/production_simulation_data/.\n",
      "****************************************\n",
      "[INFO] Processing Consumption Batch data for location: New York...\n",
      "[INFO] Checking paths for consumption batch data in New York...\n",
      "[INFO] Loaded consumption data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/batch/New York/consumption_batch_data/.\n",
      "[INFO] Writing consumption data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/New York/consumption_data/\n",
      "[INFO] Consumption data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/New York/consumption_data/.\n",
      "[INFO] Processing Production Batch data for location: New York...\n",
      "[INFO] Checking paths for production batch data in New York...\n",
      "[INFO] Loaded production data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/batch/New York/production_batch_data/.\n",
      "[INFO] Writing production data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/New York/production_data/\n",
      "[INFO] Production data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/New York/production_data/.\n",
      "****************************************\n",
      "[INFO] Processing Consumption Real-time data for location: New York...\n",
      "[INFO] Checking paths for consumption real-time data in New York...\n",
      "[INFO] Loaded consumption data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/real-time/New York/energy_consumption/.\n",
      "[INFO] Writing consumption data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/New York/energy_consumption_data/\n",
      "[INFO] Consumption data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/New York/energy_consumption_data/.\n",
      "[INFO] Processing Production Real-time data for location: New York...\n",
      "[INFO] Checking paths for production real-time data in New York...\n",
      "[INFO] Loaded production data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/real-time/New York/production_simulation/.\n",
      "[INFO] Writing production data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/New York/production_simulation_data/\n",
      "[INFO] Production data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/New York/production_simulation_data/.\n",
      "****************************************\n",
      "[INFO] Processing Consumption Batch data for location: San Francisco...\n",
      "[INFO] Checking paths for consumption batch data in San Francisco...\n",
      "[INFO] Loaded consumption data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/batch/San Francisco/consumption_batch_data/.\n",
      "[INFO] Writing consumption data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/San Francisco/consumption_data/\n",
      "[INFO] Consumption data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/San Francisco/consumption_data/.\n",
      "[INFO] Processing Production Batch data for location: San Francisco...\n",
      "[INFO] Checking paths for production batch data in San Francisco...\n",
      "[INFO] Loaded production data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/batch/San Francisco/production_batch_data/.\n",
      "[INFO] Writing production data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/San Francisco/production_data/\n",
      "[INFO] Production data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/San Francisco/production_data/.\n",
      "****************************************\n",
      "[INFO] Processing Consumption Real-time data for location: San Francisco...\n",
      "[INFO] Checking paths for consumption real-time data in San Francisco...\n",
      "[INFO] Loaded consumption data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/real-time/San Francisco/energy_consumption/.\n",
      "[INFO] Writing consumption data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/San Francisco/energy_consumption_data/\n",
      "[INFO] Consumption data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/San Francisco/energy_consumption_data/.\n",
      "[INFO] Processing Production Real-time data for location: San Francisco...\n",
      "[INFO] Checking paths for production real-time data in San Francisco...\n",
      "[INFO] Loaded production data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/real-time/San Francisco/production_simulation/.\n",
      "[INFO] Writing production data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/San Francisco/production_simulation_data/\n",
      "[INFO] Production data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/San Francisco/production_simulation_data/.\n",
      "****************************************\n",
      "[INFO] Processing Consumption Batch data for location: Chicago...\n",
      "[INFO] Checking paths for consumption batch data in Chicago...\n",
      "[INFO] Loaded consumption data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/batch/Chicago/consumption_batch_data/.\n",
      "[INFO] Writing consumption data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/Chicago/consumption_data/\n",
      "[INFO] Consumption data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/Chicago/consumption_data/.\n",
      "[INFO] Processing Production Batch data for location: Chicago...\n",
      "[INFO] Checking paths for production batch data in Chicago...\n",
      "[INFO] Loaded production data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/batch/Chicago/production_batch_data/.\n",
      "[INFO] Writing production data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/Chicago/production_data/\n",
      "[INFO] Production data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/batch/Chicago/production_data/.\n",
      "****************************************\n",
      "[INFO] Processing Consumption Real-time data for location: Chicago...\n",
      "[INFO] Checking paths for consumption real-time data in Chicago...\n",
      "[INFO] Loaded consumption data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/real-time/Chicago/energy_consumption/.\n",
      "[INFO] Writing consumption data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/Chicago/energy_consumption_data/\n",
      "[INFO] Consumption data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/Chicago/energy_consumption_data/.\n",
      "[INFO] Processing Production Real-time data for location: Chicago...\n",
      "[INFO] Checking paths for production real-time data in Chicago...\n",
      "[INFO] Loaded production data from abfss://energy-datastore@azddevstorage.dfs.core.windows.net/raw-data/real-time/Chicago/production_simulation/.\n",
      "[INFO] Writing production data to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/Chicago/production_simulation_data/\n",
      "[INFO] Production data successfully written to Delta Lake at abfss://energy-datastore@azddevstorage.dfs.core.windows.net/delta/real-time/Chicago/production_simulation_data/.\n",
      "****************************************\n",
      "[INFO] All data processed and stored in Delta Lake.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, TimestampType\n",
    "from delta import *\n",
    "\n",
    "\n",
    "\n",
    "# Locations and paths for batch and real-time data\n",
    "locations = [\"Boston\", \"New York\", \"San Francisco\", \"Chicago\"]\n",
    "batch_data_base_path = \"abfss://<container-name>@<storage-acc>.dfs.core.windows.net/raw-data/batch/\"\n",
    "real_time_data_base_path = \"abfss://<container-name>@<storage-acc>.dfs.core.windows.net/raw-data/real-time/\"\n",
    "delta_base_path = \"abfss://<container-name>@<storage-acc>.dfs.core.windows.net/delta/\"\n",
    "\n",
    "def process_data(location, data_type, data_category):\n",
    "    try:\n",
    "        # Determine the input path and schema based on data type and category (consumption/production)\n",
    "        if data_type == \"batch\":\n",
    "            if data_category == \"consumption\":\n",
    "                input_path = f\"{batch_data_base_path}{location}/consumption_batch_data/\"\n",
    "                schema = consumption_batch_schema\n",
    "                output_path = f\"{delta_base_path}batch/{location}/consumption_data/\"\n",
    "            elif data_category == \"production\":\n",
    "                input_path = f\"{batch_data_base_path}{location}/production_batch_data/\"\n",
    "                schema = production_schema\n",
    "                output_path = f\"{delta_base_path}batch/{location}/production_data/\"\n",
    "            print(f\"[INFO] Processing {data_category.capitalize()} {data_type.capitalize()} data for location: {location}...\")\n",
    "        elif data_type == \"real-time\":\n",
    "            if data_category == \"consumption\":\n",
    "                input_path = f\"{real_time_data_base_path}{location}/energy_consumption/\"\n",
    "                schema = consumption_real_time_schema\n",
    "                output_path = f\"{delta_base_path}real-time/{location}/energy_consumption_data/\"\n",
    "            elif data_category == \"production\":\n",
    "                input_path = f\"{real_time_data_base_path}{location}/production_simulation/\"\n",
    "                schema = production_schema\n",
    "                output_path = f\"{delta_base_path}real-time/{location}/production_simulation_data/\"\n",
    "            print(f\"[INFO] Processing {data_category.capitalize()} {data_type.capitalize()} data for location: {location}...\")\n",
    "        else:\n",
    "            print(\"[ERROR] Invalid data type. Please use 'batch' or 'real-time'.\")\n",
    "            return\n",
    "\n",
    "        # Check if the input path exists for the specific data category\n",
    "        print(f\"[INFO] Checking paths for {data_category} {data_type} data in {location}...\")\n",
    "\n",
    "        files = dbutils.fs.ls(input_path)  # Using dbutils to list files in the input path\n",
    "\n",
    "        # If path doesn't have files, skip processing and log the issue\n",
    "        if not files:\n",
    "            print(f\"[ERROR] No files found in {input_path} for {data_category} {data_type} data in {location}.\")\n",
    "            return\n",
    "\n",
    "        # Load the data for the given category\n",
    "        df = spark.read.format(\"csv\").option(\"header\", \"true\").schema(schema).load(input_path)\n",
    "        print(f\"[INFO] Loaded {data_category} data from {input_path}.\")\n",
    "\n",
    "        # Write the data to Delta Lake\n",
    "        print(f\"[INFO] Writing {data_category} data to Delta Lake at {output_path}\")\n",
    "        df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").partitionBy(\"location\").save(output_path)\n",
    "        print(f\"[INFO] {data_category.capitalize()} data successfully written to Delta Lake at {output_path}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error processing {data_category} {data_type} data for {location}: {e}\")\n",
    "        return\n",
    "\n",
    "# Loop through locations and process batch and real-time data for both consumption and production\n",
    "for location in locations:\n",
    "    for data_type in [\"batch\", \"real-time\"]:\n",
    "        for data_category in [\"consumption\", \"production\"]:\n",
    "            process_data(location, data_type, data_category)\n",
    "        print(\"**\"*20)\n",
    "\n",
    "print(\"[INFO] All data processed and stored in Delta Lake.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6c957ff-8805-4401-95a9-8d95cb24682b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "upload_raw_data_to_delta_lake",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
